{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "#set the random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the triplet pairs of images\n",
    "train_triplets = pd.read_csv('train_triplets.txt', delimiter = ' ', names = ['A', 'B', 'C'], dtype=str) + '.jpg'\n",
    "test_triplets = pd.read_csv('test_triplets.txt', delimiter = ' ', names = ['A', 'B', 'C'], dtype=str) + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add labels to the training dataframe\n",
    "len = train_triplets.shape[0]\n",
    "labels = np.ones(len)\n",
    "train_triplets['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the training data switch B and C random with 0.5 chance to balance labels\n",
    "df_sample = train_triplets.sample(round(len/2))\n",
    "indicies = df_sample.index\n",
    "train_triplets.loc[indicies,'labels'] = 0\n",
    "\n",
    "#dreiecks tausch:\n",
    "df_B = train_triplets.loc[indicies, 'B']\n",
    "train_triplets.loc[indicies,'B'] = train_triplets.loc[indicies,'C']\n",
    "train_triplets.loc[indicies,'C'] = df_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(image_name):\n",
    "    \"\"\"\n",
    "        for a given image name this function returns the feature vector,\n",
    "        which was computed using the pretrained convoulutional layers of\n",
    "        ResNet50. The final feautre is obtained by averageing the pooling\n",
    "        layer obtained from RasNet50\n",
    "        \n",
    "        Args: \n",
    "            image_name: string of the image name e.g. '02345.jpg'\n",
    "            \n",
    "        returns:\n",
    "            feature_average: tf.tensor storing the features obtained\n",
    "                                from RasNet50\n",
    "    \"\"\"\n",
    "    \n",
    "    img = image.load_img(path+image_name, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    #predict whats in the image\n",
    "    features = model.predict(x)\n",
    "    \n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    feature_average = global_average_layer(features)\n",
    "    \n",
    "    return feature_average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    We want to create a new dataframe storing the features for all 5000 unique training images\n",
    "    and all 5000 unique test images as we hope to save computation time this way\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#therfore we first need to extract the unique image names for training and testing\n",
    "unique_train = np.unique(train_triplets.to_numpy()[:,0:3].flatten())\n",
    "unique_test = np.unique(test_triplets.to_numpy()[:,0:3].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new dataframe that stores the image names\n",
    "train_images = pd.DataFrame({'images': unique_train})\n",
    "test_images = pd.DataFrame({'images': unique_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 13:37:38.650990: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "100%|███████████████████████████████████████| 4999/4999 [02:58<00:00, 28.02it/s]\n"
     ]
    }
   ],
   "source": [
    "#for the training images store all the corresponding features in the dataframe\n",
    "\n",
    "model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "train_feature_0 = feature_extractor(train_images.iloc[0,0]).numpy()\n",
    "train_features = pd.DataFrame(train_feature_0)\n",
    "\n",
    "len_train = unique_train.shape[0]#number of unique images in the training set\n",
    "for i in tqdm(range(1,len_train)):\n",
    "    \n",
    "    feature_i = feature_extractor(train_images.iloc[i,0]).numpy()\n",
    "    df_feature_i = pd.DataFrame(feature_i)\n",
    "    train_features = pd.concat([train_features, df_feature_i], ignore_index = True)\n",
    "    \n",
    "#concat image names and features\n",
    "train_features = pd.concat([train_images,train_features],axis=1,ignore_index = True)\n",
    "#save the dataframe\n",
    "train_features.to_csv('train_features.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4999/4999 [03:27<00:00, 24.07it/s]\n"
     ]
    }
   ],
   "source": [
    "#for the test images store all the corresponding features in the dataframe\n",
    "test_feature_0 = feature_extractor(test_images.iloc[0,0]).numpy()\n",
    "test_features = pd.DataFrame(test_feature_0)\n",
    "\n",
    "len_test = unique_test.shape[0]#number of unique images in the training set\n",
    "for i in tqdm(range(1,len_test)):\n",
    "    \n",
    "    feature_i = feature_extractor(test_images.iloc[i,0]).numpy()\n",
    "    df_feature_i = pd.DataFrame(feature_i)\n",
    "    test_features = pd.concat([test_features, df_feature_i], ignore_index = True)\n",
    "    \n",
    "#concat image names and features\n",
    "test_features = pd.concat([test_images,test_features],axis=1, ignore_index = True)\n",
    "#save the dataframe\n",
    "test_features.to_csv('test_features.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
